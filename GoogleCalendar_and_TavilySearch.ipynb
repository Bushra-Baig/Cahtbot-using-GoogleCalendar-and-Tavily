{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Set your TAVILY_API_KEY\n",
        "!pip install langchain-tavily\n",
        "import os\n",
        "from langchain_tavily import TavilySearch\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = \"TAVILY_API_KEY\"  # replace with actual key\n",
        "tavily_tool = TavilySearch(max_results=2)\n",
        "\n",
        "# Google Calendar setup\n",
        "from googleapiclient.discovery import build\n",
        "from google.oauth2 import service_account\n",
        "from langchain.tools import tool\n",
        "\n",
        "SERVICE_ACCOUNT_FILE = '3.json'  # your service account file\n",
        "SCOPES = ['https://www.googleapis.com/auth/calendar']\n",
        "\n",
        "creds = service_account.Credentials.from_service_account_file(\n",
        "    SERVICE_ACCOUNT_FILE, scopes=SCOPES\n",
        ")\n",
        "calendar_service = build('calendar', 'v3', credentials=creds)\n",
        "\n",
        "@tool\n",
        "def calendar_tool(query: str) -> str:\n",
        "    \"\"\"Creates a calendar event (static example for now).\"\"\"\n",
        "    event = {\n",
        "        'summary': 'Test Event',\n",
        "        'start': {'dateTime': '2025-05-15T10:00:00+05:00'},\n",
        "        'end': {'dateTime': '2025-05-15T11:00:00+05:00'},\n",
        "    }\n",
        "    try:\n",
        "        created_event = calendar_service.events().insert(calendarId='primary', body=event).execute()\n",
        "        return f\"Calendar event created: {created_event.get('htmlLink')}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error creating calendar event: {e}\"\n"
      ],
      "metadata": {
        "id": "C4pRl2i5wjnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define chatbot state and LangGraph setup\n",
        "from typing import TypedDict, Literal, Union\n",
        "from langgraph.graph import StateGraph\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "class ChatState(TypedDict):\n",
        "    query: str\n",
        "    tool_choice: Literal[\"search\", \"calendar\", \"chat\"]\n",
        "    result: Union[str, None]\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", temperature=0)\n"
      ],
      "metadata": {
        "id": "iOhpd6e2xQRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tool routing and logic\n",
        "def route_tool(state: ChatState) -> ChatState:\n",
        "    prompt = f\"\"\"You are a smart router. Classify the user query into one of the following:\n",
        "    1. 'search' for web queries (e.g., 'Who won the match yesterday?')\n",
        "    2. 'calendar' for events (e.g., 'Create a meeting tomorrow at 5 PM')\n",
        "    3. 'chat' for general AI conversation\n",
        "\n",
        "    Query: \"{state['query']}\"\n",
        "    Answer with one word only: search, calendar, or chat.\n",
        "    \"\"\"\n",
        "    decision = llm.invoke(prompt).content.strip().lower()\n",
        "    return {\"query\": state[\"query\"], \"tool_choice\": decision, \"result\": None}\n",
        "\n",
        "def use_search(state: ChatState) -> ChatState:\n",
        "    result = tavily_tool.invoke(state[\"query\"])  # Tavily here\n",
        "    return {\"query\": state[\"query\"], \"tool_choice\": \"search\", \"result\": result}\n",
        "\n",
        "def use_calendar(state: ChatState) -> ChatState:\n",
        "    result = calendar_tool.invoke(state[\"query\"])\n",
        "    return {\"query\": state[\"query\"], \"tool_choice\": \"calendar\", \"result\": result}\n",
        "\n",
        "def chat_response(state: ChatState) -> ChatState:\n",
        "    result = llm.invoke(state[\"query\"]).content\n",
        "    return {\"query\": state[\"query\"], \"tool_choice\": \"chat\", \"result\": result}\n"
      ],
      "metadata": {
        "id": "C549tQDzxY7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LangGraph structure\n",
        "graph_builder = StateGraph(ChatState)\n",
        "graph_builder.set_entry_point(\"router\")\n",
        "\n",
        "graph_builder.add_node(\"router\", route_tool)\n",
        "graph_builder.add_node(\"search\", use_search)\n",
        "graph_builder.add_node(\"calendar\", use_calendar)\n",
        "graph_builder.add_node(\"chat\", chat_response)\n",
        "graph_builder.add_node(\"end\", lambda x: x)\n",
        "\n",
        "graph_builder.add_conditional_edges(\"router\", lambda s: s[\"tool_choice\"], {\n",
        "    \"search\": \"search\",\n",
        "    \"calendar\": \"calendar\",\n",
        "    \"chat\": \"chat\"\n",
        "})\n",
        "graph_builder.add_edge(\"search\", \"end\")\n",
        "graph_builder.add_edge(\"calendar\", \"end\")\n",
        "graph_builder.add_edge(\"chat\", \"end\")\n",
        "\n",
        "graph = graph_builder.compile()\n"
      ],
      "metadata": {
        "id": "SAK434DTxiOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive loop\n",
        "def chatbot_interface(user_input):\n",
        "    state = {\"query\": user_input, \"tool_choice\": \"chat\", \"result\": None}\n",
        "    result = graph.invoke(state)\n",
        "    return result[\"result\"]\n",
        "\n",
        "print(\"Chatbot started! Type 'quit' to exit.\")\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'quit':\n",
        "        break\n",
        "    response = chatbot_interface(user_input)\n",
        "    print(f\"Bot: {response}\")\n"
      ],
      "metadata": {
        "id": "2Wem7J0Vxov9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}